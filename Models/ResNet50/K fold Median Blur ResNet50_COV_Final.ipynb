{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"K fold Median Blur ResNet50_COV_Final.ipynb","provenance":[],"collapsed_sections":["-tq4fmpjhjjv"],"machine_shape":"hm","mount_file_id":"1v4EzzF0jC5KxBLXCeVrWVs1ZX200i3y0","authorship_tag":"ABX9TyNr/oEGYQPZqUt0fh1Lk/kS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Covid 19 CT scan Image classification with VGG19 pretrained model.\n","\n","Datasets: 2 public datasets stored in the folders CT_DATA (CT_COVID and CT_NonCovid) and SARS-COV-2-DATA.\n","\n","DATA-Split folder : initially used to split data from CT-DATA, but will not be used here in the final.\n"],"metadata":{"id":"OKAEInCGLn4l"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Dolzcr6P6x9X","executionInfo":{"status":"ok","timestamp":1641702193973,"user_tz":300,"elapsed":2405,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"outputs":[],"source":["from builtins import range, input\n","\n","from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, AveragePooling2D, Dropout\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.metrics import confusion_matrix, roc_curve\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import os\n","import cv2\n","from glob import glob\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","source":["cov_path = \"/content/drive/MyDrive/Colab Notebooks/CTCov/CT_Data/CT_COVID/\"\n","norm_path = \"/content/drive/MyDrive/Colab Notebooks/CTCov/CT_Data/CT_NonCOVID/\""],"metadata":{"id":"J7IRrBSLVT18","executionInfo":{"status":"ok","timestamp":1641702193974,"user_tz":300,"elapsed":6,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["IMAGE_SIZE=[224,224]\n","batch_size=32\n","#define paths\n","covid_path = '/content/drive/MyDrive/Colab Notebooks/CTCov/SARS-COV-2-Data/COVID'\n","noncovid_path = '/content/drive/MyDrive/Colab Notebooks/CTCov/SARS-COV-2-Data/NON-COVID'\n","\n","# Use glob to grab images from path .jpg or jpeg\n","cov_files = glob(cov_path + '/*')\n","norm_files = glob(norm_path + '/*')\n","\n","covid_files = glob(covid_path + '/*')\n","noncovid_files = glob(noncovid_path + '/*')"],"metadata":{"id":"GxfIiD0RzBCe","executionInfo":{"status":"ok","timestamp":1641702193975,"user_tz":300,"elapsed":6,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Fetch Images and Class Labels from Files\n","cov_labels = []\n","norm_labels = []\n","\n","cov_images=[]\n","norm_images=[]\n","\n","for i in range(len(cov_files)):\n","  image = cv2.imread(cov_files[i]) # read file \n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # arrange format as per keras\n","  image = cv2.resize(image,(224,224)) # resize as per model\n","  cov_images.append(image) # append image\n","  cov_labels.append('CT_COVID') #append class label\n","  \n","for i in range(len(norm_files)):\n","  image = cv2.imread(norm_files[i])\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  image = cv2.resize(image,(224,224))\n","  norm_images.append(image)\n","  norm_labels.append('CT_NonCOVID')"],"metadata":{"id":"cqGkd4RUUM80","executionInfo":{"status":"ok","timestamp":1641702198534,"user_tz":300,"elapsed":4565,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Fetch Images and Class Labels from Files\n","covid_labels = []\n","noncovid_labels = []\n","\n","covid_images=[]\n","noncovid_images=[]\n","\n","for i in range(len(covid_files)):\n","  image = cv2.imread(covid_files[i]) # read file \n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # arrange format as per keras\n","  image = cv2.resize(image,(224,224)) # resize as per model\n","  covid_images.append(image) # append image\n","  covid_labels.append('CT_COVID') #append class label\n","  \n","for i in range(len(noncovid_files)):\n","  image = cv2.imread(noncovid_files[i])\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  image = cv2.resize(image,(224,224))\n","  noncovid_images.append(image)\n","  noncovid_labels.append('CT_NonCOVID')"],"metadata":{"id":"4-N9Wj2P1I_t","executionInfo":{"status":"ok","timestamp":1641702211873,"user_tz":300,"elapsed":13341,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["covid_images = np.concatenate((covid_images, cov_images), axis=0)\n","noncovid_images = np.concatenate((noncovid_images, norm_images),axis=0)"],"metadata":{"id":"qt1AMYZHdRBv","executionInfo":{"status":"ok","timestamp":1641702212232,"user_tz":300,"elapsed":369,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["covid_labels = np.concatenate((covid_labels, cov_labels), axis=0)\n","noncovid_labels = np.concatenate((noncovid_labels, norm_labels),axis=0)"],"metadata":{"id":"5599smYjeAOh","executionInfo":{"status":"ok","timestamp":1641702212233,"user_tz":300,"elapsed":5,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["len(covid_images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8ZqZEsAEt0_","executionInfo":{"status":"ok","timestamp":1641702212233,"user_tz":300,"elapsed":4,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}},"outputId":"3aa00011-be5e-40b6-f507-0cc02d7a782e"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1598"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Median Blur"],"metadata":{"id":"zVXWSf-_St-a"}},{"cell_type":"code","source":["covid_images = [cv2.medianBlur(img, 5) for img in covid_images]"],"metadata":{"id":"d1HbDDt8izbf","executionInfo":{"status":"ok","timestamp":1641702213872,"user_tz":300,"elapsed":1642,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["noncovid_images = [cv2.medianBlur(img, 5) for img in noncovid_images]"],"metadata":{"id":"SJ0SDS4WizY9","executionInfo":{"status":"ok","timestamp":1641702215582,"user_tz":300,"elapsed":1712,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["covid_images = np.array(covid_images)/255\n","noncovid_images = np.array(noncovid_images)/255"],"metadata":{"id":"YDf-b5zkaD2Y","executionInfo":{"status":"ok","timestamp":1641702216977,"user_tz":300,"elapsed":1398,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Split into training and testing sets for both types of images\n","covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n","    covid_images, covid_labels, test_size=0.2)\n","noncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(\n","    noncovid_images, noncovid_labels, test_size=0.2)\n","\n","# Merge sets for both types of images\n","X_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\n","X_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\n","y_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\n","y_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n","\n","# Make labels into categories - either 0 or 1, for our model\n","y_train = LabelBinarizer().fit_transform(y_train)\n","y_train = to_categorical(y_train)\n","\n","y_test = LabelBinarizer().fit_transform(y_test)\n","y_test = to_categorical(y_test)\n"],"metadata":{"id":"0YRoS3anXZlh","executionInfo":{"status":"ok","timestamp":1641702219386,"user_tz":300,"elapsed":2412,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# ResNet50 model"],"metadata":{"id":"s4lwcXPnq1k7"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","\n","kfold = KFold(n_splits=3, shuffle=True)\n","inputs = np.concatenate((X_train, X_test), axis=0)\n","targets = np.concatenate((y_train, y_test), axis=0)\n","\n","# Building Model\n","acc_per_fold = []\n","loss_per_fold = []\n","fold_no = 1\n","\n","resnet = ResNet50(weights=\"imagenet\", include_top=False,\n","  input_tensor=Input(shape=(224, 224, 3)))\n","\n","for layer in resnet.layers:\n","      layer.trainable = False\n","\n","train_aug = ImageDataGenerator(\n","      rotation_range=20,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      horizontal_flip=True\n","  )\n","\n","for train, test in kfold.split(inputs, targets):\n","\n","  outputs = resnet.output\n","  outputs = Flatten(name=\"flatten\")(outputs)\n","  outputs = Dropout(0.5)(outputs)\n","  outputs = Dense(2, activation=\"softmax\")(outputs)\n","\n","  model = Model(inputs=resnet.input, outputs=outputs)\n","\n","\n","  model.compile(\n","          loss='categorical_crossentropy', \n","          optimizer='adam', \n","          metrics=['accuracy']\n","  )\n","\n","  \n","\n","  # Generate a print\n","  print('------------------------------------------------------------------------')\n","  print(f'Training for fold {fold_no} ...')\n","  model.fit(train_aug.flow(inputs[train], targets[train], batch_size=batch_size),\n","                    verbose=1,\n","                    epochs=100)\n","  \n","  # Generate generalization metrics\n","  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n","  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","  acc_per_fold.append(scores[1] * 100)\n","  loss_per_fold.append(scores[0])\n","\n","  # Increase fold number\n","  fold_no = fold_no + 1\n","\n","# == Provide average scores ==\n","print('------------------------------------------------------------------------')\n","print('Score per fold')\n","for i in range(0, len(acc_per_fold)):\n","  print('------------------------------------------------------------------------')\n","  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n","print('------------------------------------------------------------------------')\n","print('Average scores for all folds:')\n","print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","print(f'> Loss: {np.mean(loss_per_fold)}')\n","print('------------------------------------------------------------------------')"],"metadata":{"id":"ytpfyazDpKJX","executionInfo":{"status":"ok","timestamp":1641708298967,"user_tz":300,"elapsed":6079583,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b580cf4d-25b9-4444-dcee-efa4ad5e36be"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/100\n","68/68 [==============================] - 24s 292ms/step - loss: 1.5330 - accuracy: 0.5128\n","Epoch 2/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1194 - accuracy: 0.5398\n","Epoch 3/100\n","68/68 [==============================] - 20s 289ms/step - loss: 1.0461 - accuracy: 0.5565\n","Epoch 4/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.3497 - accuracy: 0.5295\n","Epoch 5/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.1481 - accuracy: 0.5458\n","Epoch 6/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.1349 - accuracy: 0.5654\n","Epoch 7/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.5016 - accuracy: 0.5393\n","Epoch 8/100\n","68/68 [==============================] - 21s 301ms/step - loss: 1.1990 - accuracy: 0.5696\n","Epoch 9/100\n","68/68 [==============================] - 20s 301ms/step - loss: 1.0389 - accuracy: 0.5961\n","Epoch 10/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.5369 - accuracy: 0.5468\n","Epoch 11/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.2073 - accuracy: 0.5621\n","Epoch 12/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2733 - accuracy: 0.5598\n","Epoch 13/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1730 - accuracy: 0.5817\n","Epoch 14/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2501 - accuracy: 0.5724\n","Epoch 15/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1947 - accuracy: 0.5863\n","Epoch 16/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1775 - accuracy: 0.5840\n","Epoch 17/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2525 - accuracy: 0.5793\n","Epoch 18/100\n","68/68 [==============================] - 20s 289ms/step - loss: 1.4527 - accuracy: 0.5607\n","Epoch 19/100\n","68/68 [==============================] - 20s 289ms/step - loss: 1.1559 - accuracy: 0.5993\n","Epoch 20/100\n","68/68 [==============================] - 20s 289ms/step - loss: 1.2450 - accuracy: 0.5821\n","Epoch 21/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.3891 - accuracy: 0.5635\n","Epoch 22/100\n","68/68 [==============================] - 20s 290ms/step - loss: 1.2616 - accuracy: 0.5691\n","Epoch 23/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.1593 - accuracy: 0.5952\n","Epoch 24/100\n","68/68 [==============================] - 20s 289ms/step - loss: 1.0655 - accuracy: 0.5989\n","Epoch 25/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.2226 - accuracy: 0.5672\n","Epoch 26/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2160 - accuracy: 0.5835\n","Epoch 27/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.4920 - accuracy: 0.5547\n","Epoch 28/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1933 - accuracy: 0.5905\n","Epoch 29/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.1521 - accuracy: 0.5849\n","Epoch 30/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.4673 - accuracy: 0.5719\n","Epoch 31/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2093 - accuracy: 0.6049\n","Epoch 32/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2277 - accuracy: 0.5896\n","Epoch 33/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.0748 - accuracy: 0.6138\n","Epoch 34/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.1406 - accuracy: 0.6091\n","Epoch 35/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.0855 - accuracy: 0.6007\n","Epoch 36/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2363 - accuracy: 0.6054\n","Epoch 37/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.7500 - accuracy: 0.5682\n","Epoch 38/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2308 - accuracy: 0.5966\n","Epoch 39/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1439 - accuracy: 0.5896\n","Epoch 40/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2945 - accuracy: 0.6035\n","Epoch 41/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.1568 - accuracy: 0.6021\n","Epoch 42/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.5377 - accuracy: 0.5793\n","Epoch 43/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1901 - accuracy: 0.5956\n","Epoch 44/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1971 - accuracy: 0.5942\n","Epoch 45/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2146 - accuracy: 0.6073\n","Epoch 46/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2175 - accuracy: 0.5975\n","Epoch 47/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.5237 - accuracy: 0.5821\n","Epoch 48/100\n","68/68 [==============================] - 20s 290ms/step - loss: 1.5343 - accuracy: 0.5817\n","Epoch 49/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.3343 - accuracy: 0.6003\n","Epoch 50/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2691 - accuracy: 0.6035\n","Epoch 51/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2392 - accuracy: 0.5984\n","Epoch 52/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.4830 - accuracy: 0.5993\n","Epoch 53/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1568 - accuracy: 0.6026\n","Epoch 54/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2328 - accuracy: 0.5924\n","Epoch 55/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2404 - accuracy: 0.5993\n","Epoch 56/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.6083 - accuracy: 0.5747\n","Epoch 57/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2013 - accuracy: 0.6040\n","Epoch 58/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1868 - accuracy: 0.6017\n","Epoch 59/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2742 - accuracy: 0.6059\n","Epoch 60/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1706 - accuracy: 0.6059\n","Epoch 61/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.4539 - accuracy: 0.5910\n","Epoch 62/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2570 - accuracy: 0.5993\n","Epoch 63/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.3594 - accuracy: 0.5966\n","Epoch 64/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.2079 - accuracy: 0.5980\n","Epoch 65/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.3021 - accuracy: 0.5877\n","Epoch 66/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.3461 - accuracy: 0.5886\n","Epoch 67/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.4598 - accuracy: 0.5989\n","Epoch 68/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.6616 - accuracy: 0.5938\n","Epoch 69/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2679 - accuracy: 0.6049\n","Epoch 70/100\n","68/68 [==============================] - 20s 290ms/step - loss: 1.4206 - accuracy: 0.5947\n","Epoch 71/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2872 - accuracy: 0.5966\n","Epoch 72/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.7180 - accuracy: 0.5779\n","Epoch 73/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2277 - accuracy: 0.5984\n","Epoch 74/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.3071 - accuracy: 0.6040\n","Epoch 75/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2047 - accuracy: 0.6180\n","Epoch 76/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2080 - accuracy: 0.6003\n","Epoch 77/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.3023 - accuracy: 0.6021\n","Epoch 78/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.3896 - accuracy: 0.5872\n","Epoch 79/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.3393 - accuracy: 0.5993\n","Epoch 80/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2158 - accuracy: 0.6221\n","Epoch 81/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1548 - accuracy: 0.6031\n","Epoch 82/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.3452 - accuracy: 0.5961\n","Epoch 83/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2096 - accuracy: 0.6017\n","Epoch 84/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.1887 - accuracy: 0.6226\n","Epoch 85/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.1445 - accuracy: 0.6184\n","Epoch 86/100\n","68/68 [==============================] - 20s 290ms/step - loss: 1.1383 - accuracy: 0.6231\n","Epoch 87/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.6323 - accuracy: 0.5789\n","Epoch 88/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.4929 - accuracy: 0.5756\n","Epoch 89/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.2278 - accuracy: 0.6128\n","Epoch 90/100\n","68/68 [==============================] - 20s 290ms/step - loss: 1.2223 - accuracy: 0.6031\n","Epoch 91/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1907 - accuracy: 0.6184\n","Epoch 92/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.2020 - accuracy: 0.6175\n","Epoch 93/100\n","68/68 [==============================] - 20s 290ms/step - loss: 1.2137 - accuracy: 0.5970\n","Epoch 94/100\n","68/68 [==============================] - 20s 291ms/step - loss: 1.2438 - accuracy: 0.6091\n","Epoch 95/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2298 - accuracy: 0.6133\n","Epoch 96/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.8691 - accuracy: 0.5714\n","Epoch 97/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.6000 - accuracy: 0.6054\n","Epoch 98/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.4355 - accuracy: 0.5891\n","Epoch 99/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.3914 - accuracy: 0.5998\n","Epoch 100/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2561 - accuracy: 0.5956\n","Score for fold 1: loss of 0.704190194606781; accuracy of 73.76744151115417%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/100\n","68/68 [==============================] - 23s 297ms/step - loss: 1.7853 - accuracy: 0.5091\n","Epoch 2/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.0369 - accuracy: 0.5403\n","Epoch 3/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2602 - accuracy: 0.5472\n","Epoch 4/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.5408 - accuracy: 0.5230\n","Epoch 5/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1818 - accuracy: 0.5556\n","Epoch 6/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.0243 - accuracy: 0.5658\n","Epoch 7/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2357 - accuracy: 0.5593\n","Epoch 8/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.0673 - accuracy: 0.5696\n","Epoch 9/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1202 - accuracy: 0.5621\n","Epoch 10/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1017 - accuracy: 0.5663\n","Epoch 11/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.0709 - accuracy: 0.5631\n","Epoch 12/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.0972 - accuracy: 0.5821\n","Epoch 13/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1612 - accuracy: 0.5672\n","Epoch 14/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.7537 - accuracy: 0.5505\n","Epoch 15/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3537 - accuracy: 0.5812\n","Epoch 16/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2215 - accuracy: 0.5896\n","Epoch 17/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.5414 - accuracy: 0.5612\n","Epoch 18/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.3710 - accuracy: 0.5747\n","Epoch 19/100\n","68/68 [==============================] - 20s 300ms/step - loss: 1.1965 - accuracy: 0.5691\n","Epoch 20/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1574 - accuracy: 0.5807\n","Epoch 21/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1873 - accuracy: 0.5831\n","Epoch 22/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1795 - accuracy: 0.5724\n","Epoch 23/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2088 - accuracy: 0.5854\n","Epoch 24/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2768 - accuracy: 0.5803\n","Epoch 25/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1608 - accuracy: 0.5942\n","Epoch 26/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1504 - accuracy: 0.5821\n","Epoch 27/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3738 - accuracy: 0.5738\n","Epoch 28/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2533 - accuracy: 0.5872\n","Epoch 29/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2744 - accuracy: 0.5933\n","Epoch 30/100\n","68/68 [==============================] - 20s 300ms/step - loss: 1.2569 - accuracy: 0.5793\n","Epoch 31/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1878 - accuracy: 0.5924\n","Epoch 32/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1158 - accuracy: 0.5966\n","Epoch 33/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.4846 - accuracy: 0.5607\n","Epoch 34/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.6043 - accuracy: 0.5738\n","Epoch 35/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2002 - accuracy: 0.5970\n","Epoch 36/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2172 - accuracy: 0.5891\n","Epoch 37/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3767 - accuracy: 0.5710\n","Epoch 38/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.0831 - accuracy: 0.6049\n","Epoch 39/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2678 - accuracy: 0.5900\n","Epoch 40/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.1798 - accuracy: 0.5747\n","Epoch 41/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.1698 - accuracy: 0.6003\n","Epoch 42/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.1655 - accuracy: 0.5970\n","Epoch 43/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.4352 - accuracy: 0.5728\n","Epoch 44/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3317 - accuracy: 0.5984\n","Epoch 45/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2986 - accuracy: 0.5761\n","Epoch 46/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.5314 - accuracy: 0.5733\n","Epoch 47/100\n","68/68 [==============================] - 21s 301ms/step - loss: 1.4119 - accuracy: 0.5891\n","Epoch 48/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.4620 - accuracy: 0.5938\n","Epoch 49/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.5433 - accuracy: 0.5779\n","Epoch 50/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2968 - accuracy: 0.6017\n","Epoch 51/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2147 - accuracy: 0.5966\n","Epoch 52/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1053 - accuracy: 0.6212\n","Epoch 53/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2173 - accuracy: 0.6012\n","Epoch 54/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1129 - accuracy: 0.6198\n","Epoch 55/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2630 - accuracy: 0.5896\n","Epoch 56/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2624 - accuracy: 0.6128\n","Epoch 57/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2167 - accuracy: 0.6026\n","Epoch 58/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.1054 - accuracy: 0.6138\n","Epoch 59/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2013 - accuracy: 0.5966\n","Epoch 60/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.5400 - accuracy: 0.5793\n","Epoch 61/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1706 - accuracy: 0.6045\n","Epoch 62/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.3258 - accuracy: 0.5989\n","Epoch 63/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2646 - accuracy: 0.5905\n","Epoch 64/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.4337 - accuracy: 0.5993\n","Epoch 65/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3003 - accuracy: 0.6059\n","Epoch 66/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.2321 - accuracy: 0.5928\n","Epoch 67/100\n","68/68 [==============================] - 21s 302ms/step - loss: 1.2742 - accuracy: 0.5980\n","Epoch 68/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.0959 - accuracy: 0.6189\n","Epoch 69/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.5067 - accuracy: 0.5789\n","Epoch 70/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1852 - accuracy: 0.6114\n","Epoch 71/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1806 - accuracy: 0.5984\n","Epoch 72/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2926 - accuracy: 0.6012\n","Epoch 73/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.1114 - accuracy: 0.6235\n","Epoch 74/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3424 - accuracy: 0.5952\n","Epoch 75/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1492 - accuracy: 0.6040\n","Epoch 76/100\n","68/68 [==============================] - 20s 292ms/step - loss: 1.1560 - accuracy: 0.6045\n","Epoch 77/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2566 - accuracy: 0.5956\n","Epoch 78/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.3132 - accuracy: 0.5942\n","Epoch 79/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.5020 - accuracy: 0.6021\n","Epoch 80/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2643 - accuracy: 0.6105\n","Epoch 81/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.4302 - accuracy: 0.5807\n","Epoch 82/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2061 - accuracy: 0.6142\n","Epoch 83/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1317 - accuracy: 0.6119\n","Epoch 84/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.3407 - accuracy: 0.5956\n","Epoch 85/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.4837 - accuracy: 0.5845\n","Epoch 86/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.3229 - accuracy: 0.6026\n","Epoch 87/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1622 - accuracy: 0.6021\n","Epoch 88/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.3301 - accuracy: 0.5905\n","Epoch 89/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.7925 - accuracy: 0.5789\n","Epoch 90/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2520 - accuracy: 0.6026\n","Epoch 91/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.3217 - accuracy: 0.5952\n","Epoch 92/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1418 - accuracy: 0.6184\n","Epoch 93/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.6559 - accuracy: 0.5835\n","Epoch 94/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3927 - accuracy: 0.6017\n","Epoch 95/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2176 - accuracy: 0.6184\n","Epoch 96/100\n","68/68 [==============================] - 20s 302ms/step - loss: 1.2558 - accuracy: 0.6226\n","Epoch 97/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.5232 - accuracy: 0.5980\n","Epoch 98/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1891 - accuracy: 0.5938\n","Epoch 99/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2148 - accuracy: 0.5956\n","Epoch 100/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.2404 - accuracy: 0.6012\n","Score for fold 2: loss of 0.6193240284919739; accuracy of 71.53488397598267%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/100\n","68/68 [==============================] - 23s 296ms/step - loss: 1.8561 - accuracy: 0.5135\n","Epoch 2/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.0552 - accuracy: 0.5540\n","Epoch 3/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.2131 - accuracy: 0.5284\n","Epoch 4/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1771 - accuracy: 0.5447\n","Epoch 5/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1000 - accuracy: 0.5377\n","Epoch 6/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1857 - accuracy: 0.5512\n","Epoch 7/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.1540 - accuracy: 0.5549\n","Epoch 8/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1602 - accuracy: 0.5540\n","Epoch 9/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1101 - accuracy: 0.5753\n","Epoch 10/100\n","68/68 [==============================] - 20s 300ms/step - loss: 1.2870 - accuracy: 0.5484\n","Epoch 11/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.4175 - accuracy: 0.5674\n","Epoch 12/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2670 - accuracy: 0.5674\n","Epoch 13/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2006 - accuracy: 0.5684\n","Epoch 14/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1770 - accuracy: 0.5665\n","Epoch 15/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1735 - accuracy: 0.5628\n","Epoch 16/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.0840 - accuracy: 0.5842\n","Epoch 17/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.3123 - accuracy: 0.5647\n","Epoch 18/100\n","68/68 [==============================] - 20s 304ms/step - loss: 1.2422 - accuracy: 0.5591\n","Epoch 19/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.0908 - accuracy: 0.5795\n","Epoch 20/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.0419 - accuracy: 0.6033\n","Epoch 21/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.1354 - accuracy: 0.5912\n","Epoch 22/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.0870 - accuracy: 0.5688\n","Epoch 23/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.4195 - accuracy: 0.5740\n","Epoch 24/100\n","68/68 [==============================] - 20s 293ms/step - loss: 1.1036 - accuracy: 0.5902\n","Epoch 25/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1906 - accuracy: 0.5902\n","Epoch 26/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1629 - accuracy: 0.5967\n","Epoch 27/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.4517 - accuracy: 0.5721\n","Epoch 28/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1858 - accuracy: 0.5805\n","Epoch 29/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.5905 - accuracy: 0.5772\n","Epoch 30/100\n","68/68 [==============================] - 21s 303ms/step - loss: 1.1410 - accuracy: 0.5958\n","Epoch 31/100\n","68/68 [==============================] - 20s 299ms/step - loss: 0.9869 - accuracy: 0.6279\n","Epoch 32/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.0537 - accuracy: 0.6019\n","Epoch 33/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.0906 - accuracy: 0.5907\n","Epoch 34/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2155 - accuracy: 0.5907\n","Epoch 35/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.5463 - accuracy: 0.5749\n","Epoch 36/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3087 - accuracy: 0.5958\n","Epoch 37/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2925 - accuracy: 0.5907\n","Epoch 38/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1902 - accuracy: 0.5916\n","Epoch 39/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1642 - accuracy: 0.6112\n","Epoch 40/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.0746 - accuracy: 0.6005\n","Epoch 41/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.4476 - accuracy: 0.5730\n","Epoch 42/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.6392 - accuracy: 0.5605\n","Epoch 43/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.4369 - accuracy: 0.5726\n","Epoch 44/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.2567 - accuracy: 0.5963\n","Epoch 45/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.4642 - accuracy: 0.5702\n","Epoch 46/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.3273 - accuracy: 0.5819\n","Epoch 47/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3045 - accuracy: 0.5930\n","Epoch 48/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.5074 - accuracy: 0.5874\n","Epoch 49/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2756 - accuracy: 0.5926\n","Epoch 50/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.4306 - accuracy: 0.5902\n","Epoch 51/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1702 - accuracy: 0.6056\n","Epoch 52/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.6772 - accuracy: 0.5833\n","Epoch 53/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.3044 - accuracy: 0.5912\n","Epoch 54/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.3603 - accuracy: 0.5949\n","Epoch 55/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.5218 - accuracy: 0.6000\n","Epoch 56/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.2274 - accuracy: 0.6098\n","Epoch 57/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1440 - accuracy: 0.6065\n","Epoch 58/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.1862 - accuracy: 0.6191\n","Epoch 59/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.4183 - accuracy: 0.5958\n","Epoch 60/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.4801 - accuracy: 0.5898\n","Epoch 61/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.1702 - accuracy: 0.6237\n","Epoch 62/100\n","68/68 [==============================] - 20s 300ms/step - loss: 1.2934 - accuracy: 0.6088\n","Epoch 63/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3908 - accuracy: 0.5972\n","Epoch 64/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2502 - accuracy: 0.6065\n","Epoch 65/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1682 - accuracy: 0.6116\n","Epoch 66/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1344 - accuracy: 0.6186\n","Epoch 67/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3749 - accuracy: 0.5851\n","Epoch 68/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1711 - accuracy: 0.6102\n","Epoch 69/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3292 - accuracy: 0.5874\n","Epoch 70/100\n","68/68 [==============================] - 20s 304ms/step - loss: 1.5254 - accuracy: 0.5707\n","Epoch 71/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2686 - accuracy: 0.6037\n","Epoch 72/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3960 - accuracy: 0.6037\n","Epoch 73/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.1667 - accuracy: 0.6214\n","Epoch 74/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.3979 - accuracy: 0.5972\n","Epoch 75/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.4616 - accuracy: 0.6121\n","Epoch 76/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2752 - accuracy: 0.5926\n","Epoch 77/100\n","68/68 [==============================] - 20s 300ms/step - loss: 1.3842 - accuracy: 0.6014\n","Epoch 78/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.1833 - accuracy: 0.6177\n","Epoch 79/100\n","68/68 [==============================] - 20s 302ms/step - loss: 1.3480 - accuracy: 0.5814\n","Epoch 80/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3111 - accuracy: 0.5953\n","Epoch 81/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2070 - accuracy: 0.6205\n","Epoch 82/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2190 - accuracy: 0.6112\n","Epoch 83/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.3480 - accuracy: 0.6195\n","Epoch 84/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.3702 - accuracy: 0.5805\n","Epoch 85/100\n","68/68 [==============================] - 20s 295ms/step - loss: 1.2323 - accuracy: 0.6167\n","Epoch 86/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2025 - accuracy: 0.6084\n","Epoch 87/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.3640 - accuracy: 0.5879\n","Epoch 88/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.3636 - accuracy: 0.5921\n","Epoch 89/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1684 - accuracy: 0.6344\n","Epoch 90/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.2315 - accuracy: 0.6135\n","Epoch 91/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2370 - accuracy: 0.6019\n","Epoch 92/100\n","68/68 [==============================] - 20s 296ms/step - loss: 1.0601 - accuracy: 0.6493\n","Epoch 93/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2574 - accuracy: 0.5921\n","Epoch 94/100\n","68/68 [==============================] - 20s 299ms/step - loss: 1.2754 - accuracy: 0.6158\n","Epoch 95/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.3839 - accuracy: 0.6116\n","Epoch 96/100\n","68/68 [==============================] - 20s 294ms/step - loss: 1.1283 - accuracy: 0.6163\n","Epoch 97/100\n","68/68 [==============================] - 20s 298ms/step - loss: 1.2024 - accuracy: 0.6256\n","Epoch 98/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.1264 - accuracy: 0.6288\n","Epoch 99/100\n","68/68 [==============================] - 20s 301ms/step - loss: 1.3695 - accuracy: 0.5991\n","Epoch 100/100\n","68/68 [==============================] - 20s 297ms/step - loss: 1.2435 - accuracy: 0.5986\n","Score for fold 3: loss of 0.6467859745025635; accuracy of 74.76722598075867%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.704190194606781 - Accuracy: 73.76744151115417%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.6193240284919739 - Accuracy: 71.53488397598267%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.6467859745025635 - Accuracy: 74.76722598075867%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 73.35651715596516 (+- 1.3512100325820209)\n","> Loss: 0.6567667325337728\n","------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","metrics = pd.DataFrame(acc_per_fold)\n","metrics = metrics.rename(columns={0:'accuracy'})\n","loss_df = pd.DataFrame(loss_per_fold)"],"metadata":{"id":"jIErDznxMbLq","executionInfo":{"status":"ok","timestamp":1641708298967,"user_tz":300,"elapsed":19,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["metrics.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"vGvi5vgkM2o3","executionInfo":{"status":"ok","timestamp":1641708298968,"user_tz":300,"elapsed":6,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}},"outputId":"6a5d9588-12af-434d-ea88-eca3454e2047"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-6ba6171d-24b2-434f-bb62-360a6c5f04a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>73.767442</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>71.534884</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>74.767226</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ba6171d-24b2-434f-bb62-360a6c5f04a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ba6171d-24b2-434f-bb62-360a6c5f04a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ba6171d-24b2-434f-bb62-360a6c5f04a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    accuracy\n","0  73.767442\n","1  71.534884\n","2  74.767226"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["metrics_df = metrics.join(loss_df.rename(columns={0:'loss'}))"],"metadata":{"id":"sSM44Q9aM51z","executionInfo":{"status":"ok","timestamp":1641708299191,"user_tz":300,"elapsed":228,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["metrics_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"YSh4sEE1NPxz","executionInfo":{"status":"ok","timestamp":1641708299191,"user_tz":300,"elapsed":3,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}},"outputId":"545ef1fe-cfb2-47d1-b4c0-b957f08e9b40"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5b7d857b-5d02-4fc3-a2c2-940c94bce610\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>73.767442</td>\n","      <td>0.704190</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>71.534884</td>\n","      <td>0.619324</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>74.767226</td>\n","      <td>0.646786</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b7d857b-5d02-4fc3-a2c2-940c94bce610')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5b7d857b-5d02-4fc3-a2c2-940c94bce610 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5b7d857b-5d02-4fc3-a2c2-940c94bce610');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    accuracy      loss\n","0  73.767442  0.704190\n","1  71.534884  0.619324\n","2  74.767226  0.646786"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["report_csv_file = '/content/drive/MyDrive/Colab Notebooks/CTCov/Fold/ResNet50/res_med_blur_class_report.csv'\n","with open(report_csv_file, mode='w') as f:\n","    metrics_df.to_csv(f)"],"metadata":{"id":"m_i-lJcSOMOM","executionInfo":{"status":"ok","timestamp":1641708299571,"user_tz":300,"elapsed":383,"user":{"displayName":"Jeremy Qin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13619130176787951684"}}},"execution_count":18,"outputs":[]}]}